---
title: "DATA_621_HW1"
author: "Euclid Zhang"
date: "1/30/2022"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r include=FALSE}
library("corrplot")
library(MASS)
```

```{r}
train_raw_df <- read.csv("https://raw.githubusercontent.com/ezaccountz/DATA_621/main/HW1/moneyball-training-data.csv")
test_raw_df <- read.csv("https://raw.githubusercontent.com/ezaccountz/DATA_621/main/HW1/moneyball-evaluation-data.csv")

train_raw_df$INDEX <- NULL
test_raw_df$INDEX <- NULL
```


# DATA EXPLORATION

```{r}
summary(train_raw_df)
```
## * **Outliers**

From the summaries The maximum values for TEAM_PITCHING_H, TEAM_PITCHING_BB, TEAM_PITCHING_SO and TEAM_FIELDING_E seem abnormally large. There may be outliers in the columns. We can confirm this finding by checking the distributions of the values:

```{r fig.height=10, fig.width=10}
par(mfrow=c(4,4))
for(i in c(1:16)) {
  boxplot(train_raw_df[,i],main=colnames(train_raw_df)[i])
}
```
From the boxplots, there are indeed values in TEAM_PITCHING_H, TEAM_PITCHING_BB, TEAM_PITCHING_SO and TEAM_FIELDING_E that are extremly off from the majority of the data. We would handle these outliers later with the other problems.
  


## * **Missing values**

From the summaries, we see that are are missing values for TEAM_BATTING_SO, TEAM_BASERUN_SB, TEAM_BASERUN_CS, EAM_BATTING_HBP, TEAM_PITCHING_SO, and TEAM_FIELDING_DP. Now we check the portion of missing data in each field:

```{r}
sapply(train_raw_df,function(x)sum(is.na(x)))/nrow(train_raw_df)
```
91.6% of the data in TEAM_BATTING_HBP are missing. Since the minimum of TEAM_BATTING_HBP is 29, it is not plausible that the missing values are all 0. We will drop this field from our analysis as there are too many missing values and there is no good way of imputing the values.
  
For TEAM_BATTING_SO, TEAM_BASERUN_SB, TEAM_BASERUN_CS, TEAM_PITCHING_SO, and TEAM_FIELDING_DP, we will do imputation and may be handled with other problems.
  




## * **Correlations**

Now let's look at the correlations between the variables  
```{r fig.height=10, fig.width=10}
corrplot(cor(train_raw_df, use = "na.or.complete"), method = 'number', type = 'lower', diag = FALSE, tl.srt = 0.1)
```
**The following variables are nearly perfectly correlated**  

* TEAM_BATTING_H and TEAM_PITCHING_H
* TEAM_BATTING_HR and TEAM_PITCHING_HR
* TEAM_BATTING_BB and TEAM_PITCHING_BB
* TEAM_BATTING_SO and TEAM_PITCHING_SO

  

We take a more careful look at the correlation between the TARGET_WINS and other variables, and compare it with the theoretical effects
```{r paged.print=FALSE}
corr_table <- data.frame(correlation_with_TARGET_WINS = round(cor(train_raw_df, use = "na.or.complete"),4)[-1,"TARGET_WINS"])
corr_table$Theoretical_Effect <- c("Positive","Positive","Positive","Positive","Positive","Negative","Positive","Negative","Positive","Negative","Negative","Negative","Positive","Negative","Positive")
corr_table
```
**The following variables do not have correlation matching with the theoretical effect:  

* TEAM_BATTING_3B
* TEAM_PITCHING_H
* TEAM_PITCHING_HR
* TEAM_PITCHING_BB
* TEAM_PITCHING_SO
* TEAM_FIELDING_DP  
  
For TEAM_BATTING_3B and TEAM_FIELDING_DP, we would need to perform deeper analysis on this finding.  
For TEAM_PITCHING_H, TEAM_PITCHING_HR, TEAM_PITCHING_BB, TEAM_PITCHING_SO, we may consider dropping the variables since they are amlost perfectly correlated with one other variable. Also, TEAM_PITCHING_H, TEAM_PITCHING_BB and TEAM_PITCHING_SO have outlier problem as found above.

## * **normalities**

We check the normalities of the variables to determine if transformation is needed.  
```{r fig.height=10, fig.width=10}
par(mfrow=c(4,4))
for(i in c(1:16)) {
  plot(density(train_raw_df[,i],na.rm=TRUE),main=colnames(train_raw_df)[i])
}
```
TEAM_PITCHING_H, TEAM_PITCHING_BB, TEAM_PITCHING_SO and TEAM_FIELDING_E are largely right skewed because of the outliers. We will check the distributions later again when the outliers are handled.  
TEAM_BATTING_HR, TEAM_BATTING_SO, TEAM_PITCHING_HR are bimodal that may need to be transformed.  
There are some variables such as TEAM_BASERUN_SB that are slightly right skewed. We may keep them as it for easier interpretation of the result.



# DATA PREPARATION

## * **Dropping variables**

**TEAM_BATTING_HBP** is dropped for the following reason(s)

* 91.6% of the data are missing

**TEAM_PITCHING_HR** is dropped for the following reason(s) 

* nearly perfectly correlated with one other variable
* do not have correlation matching with the theoretical effect
  
**TEAM_PITCHING_H*,*TEAM_PITCHING_BB*,*TEAM_PITCHING_SO** are dropped for the following reason(s) 

* nearly perfectly correlated with one other variable
* do not have correlation matching with the theoretical effect
* large outliers

```{r}
train_prepared_df <- train_raw_df
train_prepared_df$TEAM_BATTING_HBP <- NULL
train_prepared_df$TEAM_PITCHING_HR <- NULL
train_prepared_df$TEAM_PITCHING_H <- NULL
train_prepared_df$TEAM_PITCHING_BB <- NULL
train_prepared_df$TEAM_PITCHING_SO <- NULL
```

## * **Transforming variables**

Since **TEAM_FIELDING_E** is extremely right skewed, we will transform the variable using Box-Cox transformation
 
The optimal lamba from the following result plot is near -1, so we will transform the variable using the power of -1  

```{r fig.height=4, fig.width=5}
boxcox(lm(train_prepared_df$TEAM_FIELDING_E ~ 1))
```
```{r}
train_prepared_df$TEAM_FIELDING_E_Transformed <- train_prepared_df$TEAM_FIELDING_E^(-1)
train_prepared_df$TEAM_FIELDING_E <- NULL
```
  
The following density plot and box plot show that the distribution is closer to normal and there are no extreme ourliers.
```{r fig.height=3, fig.width=6}
par(mfrow=c(1,2))
plot(density(train_prepared_df$TEAM_FIELDING_E_Transformed),main="",xlab="")
boxplot(train_prepared_df$TEAM_FIELDING_E_Transformed,main="")
```

Since **TEAM_BATTING_H** also counts the number of **TEAM_BATTING_2B**, **TEAM_BATTING_3B** and **TEAM_BATTING_3B**.  
Instead of using **TEAM_BATTING_H**, we will create a new variable **TEAM_BATTING_1B** by subtracting **TEAM_BATTING_2B**, **TEAM_BATTING_3B** and **TEAM_BATTING_3B** from **TEAM_BATTING_H**

```{r}
train_prepared_df$TEAM_BATTING_1B <- train_prepared_df$TEAM_BATTING_H - train_prepared_df$TEAM_BATTING_2B - train_prepared_df$TEAM_BATTING_3B - train_prepared_df$TEAM_BATTING_HR
train_prepared_df$TEAM_BATTING_H <- NULL
```

The distribution of the new variable is slightly right skewed. We will keep it as it for now unless transformation is necessary when developing a model.

```{r fig.height=3, fig.width=6}
par(mfrow=c(1,2))
plot(density(train_prepared_df$TEAM_BATTING_1B),main="",xlab="")
boxplot(train_prepared_df$TEAM_BATTING_1B,main="")
```

## * **Imputation for Missing Values**


The only problem now is the missing values in **TEAM_BATTING_SO**, **TEAM_BASERUN_SB**, **TEAM_BASERUN_CS** and **TEAM_FIELDING_DP**


We will impute the missing values by using linear regression models. We will not go deep into evaluating these models in this project. The purpose here is to impute missing values have better explained variance than simply using the means or medians.

In the imputation models, **TARGET_WINS** is not included as an independent variable since the values are not provided in the test data set. We will need to use the same models to impute missing values in the test data set.



Since missing values may appear in multiple variables at the same time, we will impute the variable one by one.
First we build one model for each of the variables with missing values, with all 4 variables excluded from the regression.  

Then we compare the R-squared values of all models and impute the variable with the highest R-squared value in its model.
As one of the variable is imputed, we can rebuild the other models with imputed variable included in the regression.  

We repeat this process until all variables are imputed  


The R-squared values of the models for the first round are:
```{r}
lm_team_bat_so <- lm(TEAM_BATTING_SO ~ . - TARGET_WINS - TEAM_BASERUN_SB - TEAM_BASERUN_CS - TEAM_FIELDING_DP, data = train_prepared_df)
lm_team_bas_sb <- lm(TEAM_BASERUN_SB ~ . - TARGET_WINS - TEAM_BATTING_SO - TEAM_BASERUN_CS - TEAM_FIELDING_DP, data = train_prepared_df)
lm_team_bas_cs <- lm(TEAM_BASERUN_CS ~ . - TARGET_WINS - TEAM_BATTING_SO - TEAM_BASERUN_SB - TEAM_FIELDING_DP, data = train_prepared_df)
lm_team_fld_dp <- lm(TEAM_FIELDING_DP ~ . - TARGET_WINS - TEAM_BATTING_SO - TEAM_BASERUN_SB - TEAM_BASERUN_CS, data = train_prepared_df)
```
```{r}
print(paste0("TEAM_BATTING_SO - R-squared:",toString(round(summary(lm_team_bat_so)$r.squared,4))))
print(paste0("TEAM_BASERUN_SB - R-squared:",toString(round(summary(lm_team_bas_sb)$r.squared,4))))
print(paste0("TEAM_BASERUN_CS - R-squared:",toString(round(summary(lm_team_bas_cs)$r.squared,4))))
print(paste0("TEAM_FIELDING_DP - R-squared:",toString(round(summary(lm_team_fld_dp)$r.squared,4))))
```
We impute the missing values for **TEAM_BATTING_SO** and rebuild the other 3 models

```{r}
train_prepared_df[is.na(train_prepared_df$TEAM_BATTING_SO),]$TEAM_BATTING_SO <- predict(lm_team_bat_so,train_prepared_df[is.na(train_prepared_df$TEAM_BATTING_SO),])
```

The R-squared values of the models for the second round are:
```{r}
lm_team_bas_sb <- lm(TEAM_BASERUN_SB ~ . - TARGET_WINS  - TEAM_BASERUN_CS - TEAM_FIELDING_DP, data = train_prepared_df)
lm_team_bas_cs <- lm(TEAM_BASERUN_CS ~ . - TARGET_WINS  - TEAM_BASERUN_SB - TEAM_FIELDING_DP, data = train_prepared_df)
lm_team_fld_dp <- lm(TEAM_FIELDING_DP ~ . - TARGET_WINS  - TEAM_BASERUN_SB - TEAM_BASERUN_CS, data = train_prepared_df)
```
```{r}
print(paste0("TEAM_BASERUN_SB - R-squared:",toString(round(summary(lm_team_bas_sb)$r.squared,4))))
print(paste0("TEAM_BASERUN_CS - R-squared:",toString(round(summary(lm_team_bas_cs)$r.squared,4))))
print(paste0("TEAM_FIELDING_DP - R-squared:",toString(round(summary(lm_team_fld_dp)$r.squared,4))))
```
We impute the missing values for **TEAM_BASERUN_CS** and rebuild the other 2 models
```{r}
train_prepared_df[is.na(train_prepared_df$TEAM_BASERUN_CS),]$TEAM_BASERUN_CS <- predict(lm_team_bas_cs,train_prepared_df[is.na(train_prepared_df$TEAM_BASERUN_CS),])
```

The R-squared values of the models for the third round are:
```{r}
lm_team_bas_sb <- lm(TEAM_BASERUN_SB ~ . - TARGET_WINS  - TEAM_FIELDING_DP, data = train_prepared_df)
lm_team_fld_dp <- lm(TEAM_FIELDING_DP ~ . - TARGET_WINS  - TEAM_BASERUN_SB, data = train_prepared_df)
```
```{r}
print(paste0("TEAM_BASERUN_SB - R-squared:",toString(round(summary(lm_team_bas_sb)$r.squared,4))))
print(paste0("TEAM_FIELDING_DP - R-squared:",toString(round(summary(lm_team_fld_dp)$r.squared,4))))
```
After imputing **TEAM_BASERUN_SB**, we rebuild the model for **TEAM_FIELDING_DP** and finish our imputation

```{r}
train_prepared_df[is.na(train_prepared_df$TEAM_BASERUN_SB),]$TEAM_BASERUN_SB <- predict(lm_team_bas_sb,train_prepared_df[is.na(train_prepared_df$TEAM_BASERUN_SB),])
```
```{r}
lm_team_fld_dp <- lm(TEAM_FIELDING_DP ~ . - TARGET_WINS, data = train_prepared_df)
```

The R-squared values of the last model:
```{r}
print(paste0("TEAM_FIELDING_DP - R-squared:",toString(round(summary(lm_team_fld_dp)$r.squared,4))))
```
```{r}
train_prepared_df[is.na(train_prepared_df$TEAM_FIELDING_DP),]$TEAM_FIELDING_DP <- predict(lm_team_fld_dp,train_prepared_df[is.na(train_prepared_df$TEAM_FIELDING_DP),])
```




The numbers in the summary of our prepared dataset all look plausible, we are ready for our model development

```{r}
summary(train_prepared_df)
```


# BUILD MODELS


```{r}
lm_win <- lm(TARGET_WINS ~ .,data = train_prepared_df)
```




```{r}
summary(lm_win)
```



```{r}
plot(lm_win)
```



```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```

```{r}


```



















